#lang llm-lang

@(require llm-lang/backends/ollama-phi3)

Are you working correctly?

@(displayln (prompt!))
